{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 569 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction, Density Estimation and Bayesian Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nitheese Thirumoorthy\n",
    "# ASU ID : 1225417336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the needed Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Xtrain is : (11548, 28, 28)\n",
      "Shape of ytrain is : (11548,)\n",
      "\n",
      "Shape of Xtest is : (2886, 28, 28)\n",
      "Shape of ytest is : (2886,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = scipy.io.loadmat(\"train_data.mat\")\n",
    "ytrain=train_dataset['label'][0]\n",
    "Xtrain=train_dataset['data']\n",
    "print(\"Shape of Xtrain is :\",Xtrain.shape)\n",
    "print(\"Shape of ytrain is :\",ytrain.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "test_data = scipy.io.loadmat(\"test_data.mat\")\n",
    "ytest=test_data['label'][0]\n",
    "Xtest=test_data['data']\n",
    "print(\"Shape of Xtest is :\",Xtest.shape)\n",
    "print(\"Shape of ytest is :\",ytest.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Feature Extraction and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to Calculate the bright pixels to dark pixels ratio of an image.\n",
    "def brighttodark(data,T):\n",
    "    X=[]\n",
    "    for img in data:\n",
    "        bright,dark=0,0\n",
    "        for i in range(len(img)):\n",
    "            for j in range(len(img[0])):\n",
    "                if img[i][j]>T:\n",
    "                    bright+=1\n",
    "                elif img[i][j]<=T:\n",
    "                    dark+=1\n",
    "        X.append(bright/dark)\n",
    "    return np.array(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the skewness of an image.\n",
    "def skewness(data):\n",
    "    X=[]\n",
    "    for img in data:\n",
    "        x_bar=np.mean(img)\n",
    "        s=np.std(img)\n",
    "        total=0\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                total += ((img[i][j]-x_bar)**3)\n",
    "    \n",
    "        total=total/(28*28)\n",
    "        X.append(total/(s**3))\n",
    "    return np.array(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to normalize our\n",
    "def normalize(data,T):\n",
    "    Xnorm=np.array([skewness(data),brighttodark(data,T)])\n",
    "    mu=np.mean(Xnorm,axis=1)\n",
    "    mu=np.reshape(mu,(2,1))\n",
    "    Xnorm= Xnorm - mu\n",
    "    std=np.std(Xnorm,axis=1)\n",
    "    std=np.reshape(std,(2,1))\n",
    "    Xnorm = Xnorm/std\n",
    "    return Xnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When T is equal to 150\n",
      "\n",
      "Head of Train Dataframe\n",
      "\n",
      "          0         1  label\n",
      "0 -0.312630 -0.051244      3\n",
      "1  0.965460 -0.847999      3\n",
      "2  0.516517 -0.815870      3\n",
      "3  0.297382 -0.489563      3\n",
      "4  1.906885 -1.441811      3\n",
      "\n",
      "\n",
      "Head of test Dataframe\n",
      "\n",
      "          0         1  label\n",
      "0 -1.174485  1.142590      3\n",
      "1 -0.444426  0.203891      3\n",
      "2 -1.184313  1.324994      3\n",
      "3 -1.922119  2.850372      3\n",
      "4 -0.139868 -0.286138      3\n",
      "\n",
      "\n",
      "The maximum likelihood estimates for mean of 3 is \n",
      " 0   -0.379520\n",
      "1    0.358546\n",
      "dtype: float64 \n",
      "\n",
      "The maximum likelihood estimates for mean of 7 is\n",
      " 0    0.371585\n",
      "1   -0.351050\n",
      "dtype: float64 \n",
      "\n",
      "The maximum likelihood estimates for covariance of 3 is\n",
      " [[ 0.8437565  -0.91737529]\n",
      " [-0.91737529  1.10355626]] \n",
      "\n",
      "The maximum likelihood estimates for covariance of 7 is\n",
      " [[ 0.87417217 -0.72010492]\n",
      " [-0.72010492  0.64980588]] \n",
      "\n",
      "When T is equal to 200\n",
      "Head of Train Dataframe\n",
      "          0         1  label\n",
      "0 -0.312630 -0.029591      3\n",
      "1  0.965460 -0.826533      3\n",
      "2  0.516517 -0.725447      3\n",
      "3  0.297382 -0.382378      3\n",
      "4  1.906885 -1.157556      3\n",
      "\n",
      "\n",
      "Head of test Dataframe\n",
      "          0         1  label\n",
      "0 -1.174485  1.214555      3\n",
      "1 -0.444426  0.447426      3\n",
      "2 -1.184313  0.843338      3\n",
      "3 -1.922119  3.075649      3\n",
      "4 -0.139868 -0.374038      3\n",
      "\n",
      "\n",
      "The maximum likelihood estimates for mean of 3 is \n",
      " 0   -0.379520\n",
      "1    0.306744\n",
      "dtype: float64 \n",
      "\n",
      "The maximum likelihood estimates for mean of 7 is\n",
      " 0    0.371585\n",
      "1   -0.300330\n",
      "dtype: float64 \n",
      "\n",
      "The maximum likelihood estimates for covariance of 3 is\n",
      " [[ 0.8437565  -0.91624532]\n",
      " [-0.91624532  1.136679  ]] \n",
      "\n",
      "The maximum likelihood estimates for covariance of 7 is\n",
      " [[ 0.87417217 -0.72986478]\n",
      " [-0.72986478  0.68416819]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calling the functions to do feature extraction and normalization.\n",
    "train_DF=normalize(Xtrain,150)\n",
    "test_DF =normalize(Xtest,150)\n",
    "\n",
    "trainDF=pd.DataFrame(train_DF.T)\n",
    "trainDF['label']=pd.DataFrame(ytrain)\n",
    "print(\"When T is equal to 150\\n\")\n",
    "print(\"Head of Train Dataframe\\n\")\n",
    "print(trainDF.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Head of test Dataframe\\n\")\n",
    "testDF=pd.DataFrame(test_DF.T)\n",
    "testDF['label']=pd.DataFrame(ytest)\n",
    "print(testDF.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "mu_3=np.mean(trainDF[[0,1]][trainDF['label']==3])\n",
    "print(\"The maximum likelihood estimates for mean of 3 is \\n\",mu_3,\"\\n\")\n",
    "mu_7=np.mean(trainDF[[0,1]][trainDF['label']==7])\n",
    "print(\"The maximum likelihood estimates for mean of 7 is\\n\",mu_7,\"\\n\")\n",
    "\n",
    "cov_3=np.cov(trainDF[[0,1]][trainDF['label']==3].T)\n",
    "print(\"The maximum likelihood estimates for covariance of 3 is\\n\",cov_3,\"\\n\")\n",
    "cov_7=np.cov(trainDF[[0,1]][trainDF['label']==7].T)\n",
    "print(\"The maximum likelihood estimates for covariance of 7 is\\n\",cov_7,\"\\n\")\n",
    "\n",
    "\n",
    "train_DF=normalize(Xtrain,200)\n",
    "test_DF =normalize(Xtest,200)\n",
    "print(\"When T is equal to 200\\n\")\n",
    "trainDF=pd.DataFrame(train_DF.T)\n",
    "trainDF['label']=pd.DataFrame(ytrain)\n",
    "print(\"Head of Train Dataframe\")\n",
    "print(trainDF.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Head of test Dataframe\")\n",
    "testDF=pd.DataFrame(test_DF.T)\n",
    "testDF['label']=pd.DataFrame(ytest)\n",
    "print(testDF.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "mu_3=np.mean(trainDF[[0,1]][trainDF['label']==3])\n",
    "print(\"The maximum likelihood estimates for mean of 3 is \\n\",mu_3,\"\\n\")\n",
    "mu_7=np.mean(trainDF[[0,1]][trainDF['label']==7])\n",
    "print(\"The maximum likelihood estimates for mean of 7 is\\n\",mu_7,\"\\n\")\n",
    "\n",
    "cov_3=np.cov(trainDF[[0,1]][trainDF['label']==3].T)\n",
    "print(\"The maximum likelihood estimates for covariance of 3 is\\n\",cov_3,\"\\n\")\n",
    "cov_7=np.cov(trainDF[[0,1]][trainDF['label']==7].T)\n",
    "print(\"The maximum likelihood estimates for covariance of 7 is\\n\",cov_7,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the probability density function using the MLE estimates.\n",
    "three_distribution = multivariate_normal(mu_3, cov_3)\n",
    "seven_distribution = multivariate_normal(mu_7, cov_7)\n",
    "\n",
    "pdf3 = lambda x: three_distribution.pdf(x)\n",
    "pdf7 = lambda x: seven_distribution.pdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which classifies using minimum error rate classification.\n",
    "def classify(X, pof3, pof7):\n",
    "    pof3_x = pdf3(X) * pof3\n",
    "    pof7_x = pdf7(X) * pof7\n",
    "    if pof3_x >= pof7_x:\n",
    "        return 3\n",
    "    else:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the train and test results\n",
    "y_pred_train = [classify(i,0.5,0.5) for i in train_DF.T]\n",
    "y_pred_test = [classify(i,0.5,0.5) for i in test_DF.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing them in our dataframe.\n",
    "trainDF['Y_pred'] = y_pred_train\n",
    "testDF['Y_pred'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for the configuration T=150 and P(3)=P(7)==0.5 is as below\n",
      "\n",
      "The train error rate is  0.28827502597852445\n",
      "the test error rate is  0.2955647955647956\n"
     ]
    }
   ],
   "source": [
    "#Calculating the train error rate and test error rate. \n",
    "print(\"The results for the configuration T=150 and P(3)=P(7)==0.5 is as below\\n\")\n",
    "train_error_rate = np.mean(trainDF['label'] != trainDF['Y_pred'])\n",
    "print(\"The train error rate is \",train_error_rate)\n",
    "test_error_rate = np.mean(testDF['label'] != testDF['Y_pred'])\n",
    "print(\"the test error rate is \",test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating error rates for all configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " T  P(3)_and_P(7) Train_Error_rate  Test_Error_Rate\n",
      "150  (0.5, 0.5)  0.3428299272601316  0.33853083853083854\n",
      "150  (0.3, 0.7)  0.40656390717007274  0.4078309078309078\n",
      "200  (0.5, 0.5)  0.28827502597852445  0.2955647955647956\n",
      "200  (0.3, 0.7)  0.40318669899549703  0.41302841302841303\n"
     ]
    }
   ],
   "source": [
    "print(\" T\",\" P(3)_and_P(7)\",\"Train_Error_rate\",\" Test_Error_Rate\")\n",
    "for T in (150,200):\n",
    "    for P in ((0.5,0.5),(0.3,0.7)):\n",
    "        train_DF=normalize(Xtrain,T)\n",
    "        test_DF =normalize(Xtest,T)\n",
    "        trainDF=pd.DataFrame(train_DF.T)\n",
    "        trainDF['label']=pd.DataFrame(ytrain)\n",
    "        testDF=pd.DataFrame(test_DF.T)\n",
    "        testDF['label']=pd.DataFrame(ytest)\n",
    "        \n",
    "        mu_3=np.mean(trainDF[[0,1]][trainDF['label']==3])\n",
    "        mu_7=np.mean(trainDF[[0,1]][trainDF['label']==7])\n",
    "        cov_3=np.cov(trainDF[[0,1]][trainDF['label']==3].T)\n",
    "        cov_7=np.cov(trainDF[[0,1]][trainDF['label']==7].T)\n",
    "        \n",
    "        three_distribution = multivariate_normal(mu_3, cov_3)\n",
    "        seven_distribution = multivariate_normal(mu_7, cov_7)\n",
    "        pdf3 = lambda x: three_distribution.pdf(x)\n",
    "        pdf7 = lambda x: seven_distribution.pdf(x)\n",
    "        \n",
    "        y_pred_train = [classify(i,P[0],P[1]) for i in train_DF.T]\n",
    "        y_pred_test = [classify(i,P[0],P[1]) for i in test_DF.T]\n",
    "        trainDF['Y_pred'] = y_pred_train\n",
    "        testDF['Y_pred'] = y_pred_test\n",
    "        train_error_rate = np.mean(trainDF['label'] != trainDF['Y_pred'])\n",
    "        test_error_rate = np.mean(testDF['label'] != testDF['Y_pred'])\n",
    "        print(T,\"\",P,\"\",train_error_rate,\"\",test_error_rate)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
